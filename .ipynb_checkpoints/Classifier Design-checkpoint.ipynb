{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import system\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "import graphviz\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing (No need to use in case of pickle load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veriseti boyutu:  (11035, 30)\n",
      "Backstepping_1 oranı: % 7.16810149524241\n",
      "Backstepping_2 oranı: % 47.449025826914365\n",
      "Backstepping_3 oranı: % 16.683280471227913\n",
      "Backstepping_4 oranı: % 28.699592206615314\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv('dataset/flight.csv')\n",
    "data2 = pd.read_csv('dataset/flight_littleone.csv')\n",
    "data3 = pd.read_csv('dataset/flight_mustafa.csv')\n",
    "data4 = pd.read_csv('dataset/flight_ubuntu.csv')\n",
    "frames = [data1, data2, data3, data4]\n",
    "result = pd.concat(frames)\n",
    "N_B1 = np.sum(result[\"controller_ID\"] == \"Backstepping_1\")\n",
    "N_B2 = np.sum(result[\"controller_ID\"] == \"Backstepping_2\")\n",
    "N_B3 = np.sum(result[\"controller_ID\"] == \"Backstepping_3\")\n",
    "N_B4 = np.sum(result[\"controller_ID\"] == \"Backstepping_4\")\n",
    "\n",
    "print(\"Veriseti boyutu: \", result.shape)\n",
    "print(\"Backstepping_1 oranı: %\", N_B1/(N_B1+N_B2+N_B3+N_B4)*100)\n",
    "print(\"Backstepping_2 oranı: %\", N_B2/(N_B1+N_B2+N_B3+N_B4)*100)\n",
    "print(\"Backstepping_3 oranı: %\", N_B3/(N_B1+N_B2+N_B3+N_B4)*100)\n",
    "print(\"Backstepping_4 oranı: %\", N_B4/(N_B1+N_B2+N_B3+N_B4)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train boyutu:  (8529, 29)\n",
      "X_val boyutu:  (1506, 29)\n",
      "X_test boyutu:  (1000, 29)\n"
     ]
    }
   ],
   "source": [
    "N_Test = 1000\n",
    "dataset = result.values\n",
    "controller_labels = {'Backstepping_1': 0, 'Backstepping_2': 1, 'Backstepping_3': 2, 'Backstepping_4': 3}\n",
    "np.random.shuffle(dataset)\n",
    "y = np.array([controller_labels[data[-1]] for data in dataset]).reshape(-1,)\n",
    "X = dataset[:,:-1]\n",
    "\n",
    "X_test = X[0:N_Test,:]\n",
    "y_test = y[0:N_Test]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X[N_Test:,:], y[N_Test:], test_size=0.15, random_state=42)\n",
    "\n",
    "# Saving the objects:\n",
    "# with open('dataset.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "#     pickle.dump([X_train, X_val, X_test, y_train, y_val, y_test], f)\n",
    "    \n",
    "pickle.dump([X_train, X_val, X_test, y_train, y_val, y_test], open(\"dataset.pkl\",\"wb\"), protocol=2)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print (\"X_train boyutu: \",X_train.shape)\n",
    "print (\"X_val boyutu: \",X_val.shape)\n",
    "print (\"X_test boyutu: \",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.pkl', 'rb') as f:  # Python 3: open(..., 'wb')\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Train Acc: 0.762, Val Acc: 0.763, Test Acc: 0.754\n",
      "Random Forest Train Acc: 0.988, Val Acc: 0.959, Test Acc: 0.953\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"489pt\" height=\"671pt\"\r\n",
       " viewBox=\"0.00 0.00 489.00 671.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 667)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-667 485,-667 485,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"#d0f8cc\" stroke=\"black\" d=\"M388.5,-663C388.5,-663 193.5,-663 193.5,-663 187.5,-663 181.5,-657 181.5,-651 181.5,-651 181.5,-592 181.5,-592 181.5,-586 187.5,-580 193.5,-580 193.5,-580 388.5,-580 388.5,-580 394.5,-580 400.5,-586 400.5,-592 400.5,-592 400.5,-651 400.5,-651 400.5,-657 394.5,-663 388.5,-663\"/>\r\n",
       "<text text-anchor=\"start\" x=\"236.5\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">yaw_dot ≤ &#45;0.011</text>\r\n",
       "<text text-anchor=\"start\" x=\"253.5\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.661</text>\r\n",
       "<text text-anchor=\"start\" x=\"239.5\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8529</text>\r\n",
       "<text text-anchor=\"start\" x=\"189.5\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [619, 4027, 1414, 2469]</text>\r\n",
       "<text text-anchor=\"start\" x=\"215\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Backstepping_2</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#c8f7c4\" stroke=\"black\" d=\"M280.5,-544C280.5,-544 93.5,-544 93.5,-544 87.5,-544 81.5,-538 81.5,-532 81.5,-532 81.5,-473 81.5,-473 81.5,-467 87.5,-461 93.5,-461 93.5,-461 280.5,-461 280.5,-461 286.5,-461 292.5,-467 292.5,-473 292.5,-473 292.5,-532 292.5,-532 292.5,-538 286.5,-544 280.5,-544\"/>\r\n",
       "<text text-anchor=\"start\" x=\"132.5\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">yaw_dot ≤ &#45;0.011</text>\r\n",
       "<text text-anchor=\"start\" x=\"149.5\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.611</text>\r\n",
       "<text text-anchor=\"start\" x=\"135.5\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7686</text>\r\n",
       "<text text-anchor=\"start\" x=\"89.5\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [490, 4026, 712, 2458]</text>\r\n",
       "<text text-anchor=\"start\" x=\"111\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Backstepping_2</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M254.918,-579.907C246.851,-570.832 238.219,-561.121 229.906,-551.769\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"232.278,-549.17 223.018,-544.021 227.046,-553.82 232.278,-549.17\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"221.55\" y=\"-565.278\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 980 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>980</title>\r\n",
       "<path fill=\"#60b0ea\" stroke=\"black\" d=\"M469,-536.5C469,-536.5 323,-536.5 323,-536.5 317,-536.5 311,-530.5 311,-524.5 311,-524.5 311,-480.5 311,-480.5 311,-474.5 317,-468.5 323,-468.5 323,-468.5 469,-468.5 469,-468.5 475,-468.5 481,-474.5 481,-480.5 481,-480.5 481,-524.5 481,-524.5 481,-530.5 475,-536.5 469,-536.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"358.5\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.283</text>\r\n",
       "<text text-anchor=\"start\" x=\"348.5\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 843</text>\r\n",
       "<text text-anchor=\"start\" x=\"319\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [129, 1, 702, 11]</text>\r\n",
       "<text text-anchor=\"start\" x=\"320\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Backstepping_3</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;980 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>0&#45;&gt;980</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M327.429,-579.907C337.827,-568.321 349.156,-555.698 359.555,-544.111\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"362.161,-546.447 366.235,-536.667 356.951,-541.772 362.161,-546.447\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"367.584\" y=\"-557.93\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#61b1ea\" stroke=\"black\" d=\"M158,-417.5C158,-417.5 12,-417.5 12,-417.5 6,-417.5 0,-411.5 0,-405.5 0,-405.5 0,-361.5 0,-361.5 0,-355.5 6,-349.5 12,-349.5 12,-349.5 158,-349.5 158,-349.5 164,-349.5 170,-355.5 170,-361.5 170,-361.5 170,-405.5 170,-405.5 170,-411.5 164,-417.5 158,-417.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"47.5\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.294</text>\r\n",
       "<text text-anchor=\"start\" x=\"37.5\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 776</text>\r\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [113, 0, 642, 21]</text>\r\n",
       "<text text-anchor=\"start\" x=\"9\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Backstepping_3</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M151.612,-460.907C141.607,-449.432 130.715,-436.938 120.693,-425.442\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"123.124,-422.905 113.915,-417.667 117.848,-427.505 123.124,-422.905\"/>\r\n",
       "</g>\r\n",
       "<!-- 9 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>9</title>\r\n",
       "<path fill=\"#bef6b9\" stroke=\"black\" d=\"M379.5,-425C379.5,-425 200.5,-425 200.5,-425 194.5,-425 188.5,-419 188.5,-413 188.5,-413 188.5,-354 188.5,-354 188.5,-348 194.5,-342 200.5,-342 200.5,-342 379.5,-342 379.5,-342 385.5,-342 391.5,-348 391.5,-354 391.5,-354 391.5,-413 391.5,-413 391.5,-419 385.5,-425 379.5,-425\"/>\r\n",
       "<text text-anchor=\"start\" x=\"246\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">z_dot ≤ 0.008</text>\r\n",
       "<text text-anchor=\"start\" x=\"252.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.533</text>\r\n",
       "<text text-anchor=\"start\" x=\"238.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6910</text>\r\n",
       "<text text-anchor=\"start\" x=\"196.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [377, 4026, 70, 2437]</text>\r\n",
       "<text text-anchor=\"start\" x=\"214\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Backstepping_2</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;9 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M222.735,-460.907C230.725,-451.832 239.274,-442.121 247.506,-432.769\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"250.347,-434.839 254.328,-425.021 245.093,-430.214 250.347,-434.839\"/>\r\n",
       "</g>\r\n",
       "<!-- 10 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>10</title>\r\n",
       "<path fill=\"#a6f2a0\" stroke=\"black\" d=\"M277.5,-306C277.5,-306 98.5,-306 98.5,-306 92.5,-306 86.5,-300 86.5,-294 86.5,-294 86.5,-235 86.5,-235 86.5,-229 92.5,-223 98.5,-223 98.5,-223 277.5,-223 277.5,-223 283.5,-223 289.5,-229 289.5,-235 289.5,-235 289.5,-294 289.5,-294 289.5,-300 283.5,-306 277.5,-306\"/>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">z_dot ≤ 0.008</text>\r\n",
       "<text text-anchor=\"start\" x=\"150.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.505</text>\r\n",
       "<text text-anchor=\"start\" x=\"136.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6202</text>\r\n",
       "<text text-anchor=\"start\" x=\"94.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [377, 3940, 46, 1839]</text>\r\n",
       "<text text-anchor=\"start\" x=\"112\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Backstepping_2</text>\r\n",
       "</g>\r\n",
       "<!-- 9&#45;&gt;10 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>9&#45;&gt;10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M254.612,-341.907C246.7,-332.832 238.234,-323.121 230.081,-313.769\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"232.535,-311.259 223.326,-306.021 227.259,-315.859 232.535,-311.259\"/>\r\n",
       "</g>\r\n",
       "<!-- 925 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>925</title>\r\n",
       "<path fill=\"#de5cea\" stroke=\"black\" d=\"M464,-298.5C464,-298.5 320,-298.5 320,-298.5 314,-298.5 308,-292.5 308,-286.5 308,-286.5 308,-242.5 308,-242.5 308,-236.5 314,-230.5 320,-230.5 320,-230.5 464,-230.5 464,-230.5 470,-230.5 476,-236.5 476,-242.5 476,-242.5 476,-286.5 476,-286.5 476,-292.5 470,-298.5 464,-298.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"354.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.271</text>\r\n",
       "<text text-anchor=\"start\" x=\"344.5\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 708</text>\r\n",
       "<text text-anchor=\"start\" x=\"319.5\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 86, 24, 598]</text>\r\n",
       "<text text-anchor=\"start\" x=\"316\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Backstepping_4</text>\r\n",
       "</g>\r\n",
       "<!-- 9&#45;&gt;925 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>9&#45;&gt;925</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M325.388,-341.907C335.393,-330.432 346.285,-317.938 356.307,-306.442\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"359.152,-308.505 363.085,-298.667 353.876,-303.905 359.152,-308.505\"/>\r\n",
       "</g>\r\n",
       "<!-- 11 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>11</title>\r\n",
       "<path fill=\"#e88bf0\" stroke=\"black\" d=\"M161,-179.5C161,-179.5 15,-179.5 15,-179.5 9,-179.5 3,-173.5 3,-167.5 3,-167.5 3,-123.5 3,-123.5 3,-117.5 9,-111.5 15,-111.5 15,-111.5 161,-111.5 161,-111.5 167,-111.5 173,-117.5 173,-123.5 173,-123.5 173,-167.5 173,-167.5 173,-173.5 167,-179.5 161,-179.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"50.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.439</text>\r\n",
       "<text text-anchor=\"start\" x=\"36.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1243</text>\r\n",
       "<text text-anchor=\"start\" x=\"11\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 337, 36, 867]</text>\r\n",
       "<text text-anchor=\"start\" x=\"12\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Backstepping_4</text>\r\n",
       "</g>\r\n",
       "<!-- 10&#45;&gt;11 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>10&#45;&gt;11</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M153.305,-222.907C143.497,-211.432 132.819,-198.938 122.993,-187.442\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.506,-184.995 116.348,-179.667 120.184,-189.543 125.506,-184.995\"/>\r\n",
       "</g>\r\n",
       "<!-- 116 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>116</title>\r\n",
       "<path fill=\"#86ee7c\" stroke=\"black\" d=\"M373,-187C373,-187 203,-187 203,-187 197,-187 191,-181 191,-175 191,-175 191,-116 191,-116 191,-110 197,-104 203,-104 203,-104 373,-104 373,-104 379,-104 385,-110 385,-116 385,-116 385,-175 385,-175 385,-181 379,-187 373,-187\"/>\r\n",
       "<text text-anchor=\"start\" x=\"240\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">theta0 ≤ &#45;1.536</text>\r\n",
       "<text text-anchor=\"start\" x=\"250.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.428</text>\r\n",
       "<text text-anchor=\"start\" x=\"236.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4959</text>\r\n",
       "<text text-anchor=\"start\" x=\"199\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [374, 3603, 10, 972]</text>\r\n",
       "<text text-anchor=\"start\" x=\"212\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Backstepping_2</text>\r\n",
       "</g>\r\n",
       "<!-- 10&#45;&gt;116 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>10&#45;&gt;116</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M222.695,-222.907C230.451,-213.832 238.751,-204.121 246.744,-194.769\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"249.53,-196.897 253.367,-187.021 244.209,-192.349 249.53,-196.897\"/>\r\n",
       "</g>\r\n",
       "<!-- 117 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>117</title>\r\n",
       "<path fill=\"#e375ed\" stroke=\"black\" d=\"M262,-68C262,-68 118,-68 118,-68 112,-68 106,-62 106,-56 106,-56 106,-12 106,-12 106,-6 112,-0 118,-0 118,-0 262,-0 262,-0 268,-0 274,-6 274,-12 274,-12 274,-56 274,-56 274,-62 268,-68 262,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"156.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.36</text>\r\n",
       "<text text-anchor=\"start\" x=\"142.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 159</text>\r\n",
       "<text text-anchor=\"start\" x=\"121.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 36, 1, 122]</text>\r\n",
       "<text text-anchor=\"start\" x=\"114\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Backstepping_4</text>\r\n",
       "</g>\r\n",
       "<!-- 116&#45;&gt;117 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>116&#45;&gt;117</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M251.508,-103.726C243.345,-94.6054 234.686,-84.93 226.522,-75.8078\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"229.079,-73.417 219.802,-68.2996 223.863,-78.0853 229.079,-73.417\"/>\r\n",
       "</g>\r\n",
       "<!-- 144 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>144</title>\r\n",
       "<path fill=\"#80ed77\" stroke=\"black\" d=\"M466,-68C466,-68 304,-68 304,-68 298,-68 292,-62 292,-56 292,-56 292,-12 292,-12 292,-6 298,-0 304,-0 304,-0 466,-0 466,-0 472,-0 478,-6 478,-12 478,-12 478,-56 478,-56 478,-62 472,-68 466,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"351.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.41</text>\r\n",
       "<text text-anchor=\"start\" x=\"333.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4800</text>\r\n",
       "<text text-anchor=\"start\" x=\"300\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [374, 3567, 9, 850]</text>\r\n",
       "<text text-anchor=\"start\" x=\"309\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Backstepping_2</text>\r\n",
       "</g>\r\n",
       "<!-- 116&#45;&gt;144 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>116&#45;&gt;144</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M324.119,-103.726C332.199,-94.6054 340.77,-84.93 348.851,-75.8078\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"351.491,-78.1058 355.502,-68.2996 346.251,-73.4642 351.491,-78.1058\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x25c06849c48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree._tree import TREE_LEAF\n",
    "\n",
    "def prune_index(inner_tree, index, threshold):\n",
    "    if inner_tree.value[index].min() < threshold:\n",
    "        # turn node into a leaf by \"unlinking\" its children\n",
    "        inner_tree.children_left[index] = TREE_LEAF\n",
    "        inner_tree.children_right[index] = TREE_LEAF\n",
    "    # if there are shildren, visit them as well\n",
    "    if inner_tree.children_left[index] != TREE_LEAF:\n",
    "        prune_index(inner_tree, inner_tree.children_left[index], threshold)\n",
    "        prune_index(inner_tree, inner_tree.children_right[index], threshold)\n",
    "\n",
    "\n",
    "feature_names = ['pos_diffx','pos_diffy','pos_diffz', 'x_dot0','y_dot0','z_dot0', 'x_ddot0','y_ddot0','z_ddot0', 'phi0','theta0','yaw0', 'phi_dot0','theta_dot0','yaw_dot0', \n",
    "                 'x','y','z','x_dot','y_dot','z_dot', 'phi','theta','yaw', 'phi_dot','theta_dot','yaw_dot', 'Tf', 'Cost']\n",
    "\n",
    "class_names = ['Backstepping_1', 'Backstepping_2', 'Backstepping_3', 'Backstepping_4']\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "prune_index(clf.tree_, 0, 10)\n",
    "\n",
    "train_pred = clf.predict(X_train)\n",
    "val_pred = clf.predict(X_val)\n",
    "test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "train_acc = accuracy_score(y_train, train_pred)\n",
    "val_acc = accuracy_score(y_val, val_pred)\n",
    "test_acc = accuracy_score(y_test, test_pred)\n",
    "\n",
    "print (\"Decision Tree Train Acc: {0:.3}, Val Acc: {1:.3}, Test Acc: {2:.3}\".format(train_acc, val_acc, test_acc))\n",
    "\n",
    "\n",
    "forest = RandomForestClassifier(bootstrap=True, n_estimators=100, \n",
    "                                min_samples_split=12, min_samples_leaf=5, max_features=10, max_depth=80)\n",
    "forest = forest.fit(X_train, y_train)\n",
    "\n",
    "train_pred = forest.predict(X_train)\n",
    "val_pred = forest.predict(X_val)\n",
    "test_pred = forest.predict(X_test)\n",
    "\n",
    "\n",
    "train_acc = accuracy_score(y_train, train_pred)\n",
    "val_acc = accuracy_score(y_val, val_pred)\n",
    "test_acc = accuracy_score(y_test, test_pred)\n",
    "\n",
    "print (\"Random Forest Train Acc: {0:.3}, Val Acc: {1:.3}, Test Acc: {2:.3}\".format(train_acc, val_acc, test_acc))\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                      feature_names=feature_names,  \n",
    "                      class_names=class_names,  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_columns = ['Layers', 'Epochs', 'BatchSize', 'LearningRate', 'Optimizer', 'Scheduler', 'TrainAcc', 'ValAcc']\n",
    "stats_filename = 'params_results.csv'\n",
    "\n",
    "def write_results(results): \n",
    "    df_stats = pd.DataFrame([results], columns=stats_columns)\n",
    "    df_stats.to_csv(stats_filename, mode='a', index=False,header=not os.path.isfile(stats_filename))\n",
    "\n",
    "def predict(X, y, model):\n",
    "    #Validation part\n",
    "    model.eval()  # Set model to training mode\n",
    "\n",
    "    inputs, labels = torch.from_numpy(X).to(device), torch.from_numpy(y).to(device).long()\n",
    "\n",
    "    outputs = model(inputs.float())\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    accuracy = torch.sum(preds == labels.data).item() / float(inputs.size(0))\n",
    "    \n",
    "    print (\"Test data, Loss: {0:.3}, Accuracy: {1:.4}\".format(loss.item(), accuracy))\n",
    "    \n",
    "\n",
    "def shuffle_dataset(X, y):\n",
    "    p = np.random.permutation(len(X))\n",
    "    return X[p], y[p]\n",
    "\n",
    "def train_model(X, y, X_val, y_val, model, criterion, optimizer, scheduler, minibatch_size, num_epochs=25):\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    losses_train = []\n",
    "    losses_val = []\n",
    "    accuracy_train = []\n",
    "    accuracy_val = []\n",
    "    # path = F\"/content/drive/My Drive/best_model.pt\"\n",
    "#     directory = path_name\n",
    "\n",
    "#     if not os.path.exists(directory):\n",
    "#         os.makedirs(directory)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        X_train, y_train = shuffle_dataset(X, y)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        losses_iter = []\n",
    "        accuracy_iter = []\n",
    "\n",
    "        # Iterate over data.\n",
    "        for i in range(0, X_train.shape[0], minibatch_size):\n",
    "            # Get pair of (X, y) of the current minibatch/chunk             \n",
    "            X_batch = X_train[i:i + minibatch_size]\n",
    "            y_batch = y_train[i:i + minibatch_size]\n",
    "\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = torch.from_numpy(X_batch).to(device), torch.from_numpy(y_batch).to(device).long()\n",
    "\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs.float())\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            \n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # print (\"losses_iter\", loss.item() * inputs.size(0))\n",
    "            # print (\"accuracy_iter\", torch.sum(preds == labels.data).item() / float(inputs.size(0)))\n",
    "\n",
    "            losses_iter.append(loss.item())\n",
    "            accuracy_iter.append(torch.sum(preds == labels.data).item() / float(inputs.size(0)))\n",
    "        \n",
    "            scheduler.step()\n",
    "        \n",
    "        train_loss = np.mean(losses_iter)\n",
    "        train_acc = np.mean(accuracy_iter)\n",
    "\n",
    "        losses_train.append(train_loss)\n",
    "        accuracy_train.append(train_acc)\n",
    "\n",
    "\n",
    "        print('Training Loss: {:.4f} Acc: {:.4f}'.format(train_loss, train_acc))\n",
    "        \n",
    "        #Validation part\n",
    "        model.eval()  # Set model to training mode\n",
    "        \n",
    "        inputs, labels = torch.from_numpy(X_val).to(device), torch.from_numpy(y_val).to(device).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs.float())\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        val_loss = loss.item()\n",
    "        val_acc = torch.sum(preds == labels.data).item() / float(inputs.size(0))\n",
    "        \n",
    "        losses_val.append(val_loss)\n",
    "        accuracy_val.append(val_acc)\n",
    "        \n",
    "        \n",
    "        print('Validation Loss: {:.4f} Acc: {:.4f}'.format(val_loss, val_acc))\n",
    "\n",
    "#         deep copy the model\n",
    "        if val_acc > best_acc:\n",
    "            best_train_acc = train_acc\n",
    "            best_val_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            path = \"best_model.pt\"\n",
    "            torch.save(best_model_wts, path)\n",
    "\n",
    "        print()\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}s'.format(time_elapsed))\n",
    "    print('Best Train Acc: {:4f}'.format(best_train_acc))\n",
    "    print('Best Val Acc: {:4f}'.format(best_val_acc))\n",
    "    \n",
    "    \n",
    "#     stats_columns = ['Layers', 'Epochs', 'BatchSize', 'LearningRate', 'Optimizer', 'Scheduler', 'TrainAcc', 'ValAcc']\n",
    "    layers = [module for module in model.modules() if type(module) != nn.Sequential]\n",
    "    write_results([layers, num_epochs, minibatch_size, learning_rate, optimizer.state_dict, scheduler.state_dict, best_train_acc, best_val_acc])\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "Training Loss: 1.1666 Acc: 0.4855\n",
      "Validation Loss: 1.1124 Acc: 0.5060\n",
      "\n",
      "Training complete in 5s\n",
      "Best Train Acc: 0.485487\n",
      "Best Val Acc: 0.505976\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.drop_layer = nn.Dropout(p=0.4)\n",
    "        self.fc1 = nn.Linear(29, 800)\n",
    "        self.fc2 = nn.Linear(800, 400)\n",
    "        self.fc3 = nn.Linear(400, 200)\n",
    "        self.fc4 = nn.Linear(200, 100)\n",
    "        self.fc5 = nn.Linear(100, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop_layer(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.drop_layer(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.drop_layer(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.drop_layer(x)\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "n_epochs = 1\n",
    "minibatch_size = 16\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "model = Net()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, X_train.shape[0], eta_min=learning_rate)\n",
    "final_mode = train_model(X_train, y_train, X_val, y_val, model, criterion, optimizer, scheduler, minibatch_size, num_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='rbf')\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "svc = svc.fit(X_train, y_train)\n",
    "\n",
    "train_pred = svc.predict(X_train)\n",
    "val_pred = svc.predict(X_val)\n",
    "test_pred = svc.predict(X_test)\n",
    "\n",
    "\n",
    "train_acc = accuracy_score(y_train, train_pred)\n",
    "val_acc = accuracy_score(y_val, val_pred)\n",
    "test_acc = accuracy_score(y_test, test_pred)\n",
    "\n",
    "print (\"SVM Train Acc: {0:.3}, Val Acc: {1:.3}, Test Acc: {2:.3}\".format(train_acc, val_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
